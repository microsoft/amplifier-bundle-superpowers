# Per-Task Pipeline Sub-Recipe
# Implements a single task through the full pipeline:
#   1. Implement with TDD (fresh agent)
#   2. Spec compliance review loop (iterate until APPROVED)
#   3. Code quality review loop (iterate until APPROVED)
#
# Called by subagent-driven-development.yaml via foreach.
# Each task goes through the FULL pipeline before the next task starts.

name: "per-task-pipeline"
description: "Execute single task: implement with TDD, spec compliance review, code quality review"
version: "1.0.0"
author: "Superpowers Bundle"
tags: ["implementation", "subagent", "tdd", "review", "per-task"]

context:
  current_task: ""  # Required: task specification passed from parent foreach
  spec_verdict: ""  # Initialized empty; set by spec-review while_steps
  quality_verdict: ""  # Initialized empty; set by quality-review while_steps

stages:
  - name: "pipeline"
    steps:
      # --- Step 1: Implement the task ---
      - id: "implement"
        agent: "superpowers:implementer"
        prompt: |
          SUBAGENT IMPLEMENTATION TASK
          ============================

          You are a fresh agent assigned to implement ONE specific task.
          Focus ONLY on this task. Do not consider other tasks.

          TASK TO IMPLEMENT:
          {{current_task}}

          IMPLEMENTATION REQUIREMENTS:
          1. FOLLOW TDD (Test-Driven Development):
             - Write failing tests FIRST based on the spec
             - Implement code to make tests pass
             - Refactor if needed while keeping tests green
          2. FOLLOW THE SPEC EXACTLY:
             - Implement exactly what the spec says
             - Do not add features not in the spec
             - Do not skip any spec requirements
          3. VERIFY BEFORE COMPLETING:
             - Run the tests you wrote
             - Confirm they pass
             - Commit your changes

          OUTPUT FORMAT:
          Return your implementation results including:
          - task_id: Which task was implemented
          - files_changed: [list of files created/modified]
          - tests_written: [list of test files/functions]
          - test_results: pass/fail with details
          - implementation_notes: Key decisions or notes
          - spec_coverage: How each spec requirement was addressed
        output: "task_implementation"
        timeout: 900

      # --- Step 2: Spec compliance review loop ---
      - id: "spec-review-loop"
        type: "bash"
        command: "true"
        while_condition: "not {{spec_verdict}} contains APPROVED"
        break_when: "{{spec_verdict}} contains APPROVED"
        max_while_iterations: 3
        while_steps:
          - id: "spec-review"
            agent: "superpowers:spec-reviewer"
            prompt: |
              SPEC COMPLIANCE REVIEW
              ======================
              Review Stage 1 of 2: Verify implementation matches specification EXACTLY.

              TASK SPEC:
              {{current_task}}

              IMPLEMENTATION RESULT:
              {{task_implementation}}

              YOUR MISSION:
              1. Read the ACTUAL CODE (do not trust the implementation report)
              2. Compare every spec requirement against what was implemented
              3. Run the test suite and read the full output
              4. Check for missing requirements AND extra features

              VERDICT FORMAT:
              End your review with exactly one of:
              - "VERDICT: APPROVED" — spec fully implemented, nothing extra
              - "VERDICT: NEEDS CHANGES — [list specific issues]"
            output: "spec_verdict"
            timeout: 600

          - id: "spec-fix"
            condition: "{{spec_verdict}} contains NEEDS CHANGES"
            agent: "superpowers:implementer"
            prompt: |
              SPEC COMPLIANCE FIX
              ====================
              The spec reviewer found issues with your implementation.

              REVIEW FEEDBACK:
              {{spec_verdict}}

              ORIGINAL TASK:
              {{current_task}}

              Fix ONLY the issues identified. Do not add anything else.
              Run tests after fixing. Commit your changes.

              Return updated implementation results.
            output: "task_implementation"
            timeout: 600

      # --- Step 2b: Check if spec review exhausted without approval ---
      - id: "check-spec-resolution"
        condition: "{{spec_verdict}} contains NEEDS CHANGES"
        agent: "superpowers:plan-writer"
        prompt: |
          WARNING: Spec review loop exhausted after 3 iterations without approval.
          Task: {{current_task}}
          Last spec verdict: {{spec_verdict}}

          Flag this task as having unresolved spec issues. Include this warning
          in the task summary so the human reviewer is aware during the approval gate.
        output: "spec_unresolved"
        timeout: 300

      # --- Step 3: Code quality review loop ---
      - id: "quality-review-loop"
        type: "bash"
        command: "true"
        while_condition: "not {{quality_verdict}} contains APPROVED"
        break_when: "{{quality_verdict}} contains APPROVED"
        max_while_iterations: 3
        while_steps:
          - id: "quality-review"
            agent: "superpowers:code-quality-reviewer"
            prompt: |
              CODE QUALITY REVIEW
              ===================
              Review Stage 2 of 2: Verify code quality and best practices.
              Spec compliance has already been verified.

              TASK:
              {{current_task}}

              IMPLEMENTATION:
              {{task_implementation}}

              YOUR MISSION:
              1. Read the ACTUAL CODE
              2. Run the test suite and read the full output
              3. Check: clean code, DRY, error handling, test quality, maintainability
              4. Do NOT change spec behavior — only refactor for quality

              VERDICT FORMAT:
              End your review with exactly one of:
              - "VERDICT: APPROVED" — code quality meets standards
              - "VERDICT: NEEDS CHANGES — [list specific issues by severity]"

              Minor/suggestion issues do NOT block approval.
              Only critical and major issues require NEEDS CHANGES.
            output: "quality_verdict"
            timeout: 600

          - id: "quality-fix"
            condition: "{{quality_verdict}} contains NEEDS CHANGES"
            agent: "superpowers:implementer"
            prompt: |
              CODE QUALITY FIX
              =================
              The code quality reviewer found issues.

              REVIEW FEEDBACK:
              {{quality_verdict}}

              ORIGINAL TASK:
              {{current_task}}

              Fix ONLY the quality issues identified. Do NOT change spec behavior.
              Run tests after fixing. Commit your changes.

              Return updated implementation results.
            output: "task_implementation"
            timeout: 600

      # --- Step 3b: Check if quality review exhausted without approval ---
      - id: "check-quality-resolution"
        condition: "{{quality_verdict}} contains NEEDS CHANGES"
        agent: "superpowers:plan-writer"
        prompt: |
          WARNING: Quality review loop exhausted after 3 iterations without approval.
          Task: {{current_task}}
          Last quality verdict: {{quality_verdict}}

          Flag this task as having unresolved quality issues. Include this warning
          in the task summary so the human reviewer is aware during the approval gate.
        output: "quality_unresolved"
        timeout: 300
